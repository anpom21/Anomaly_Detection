{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d483051a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layered images shape: (500, 4, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "from src.Autoencoder import Autoencoder\n",
    "from src.Dataloader import Dataloader \n",
    "import torch\n",
    "model = Autoencoder(4)\n",
    "dataloader = Dataloader(\"Datasets/Dataset003/Train\",24, 224, 224, True)\n",
    "\n",
    "n_images = 4\n",
    "images = dataloader.load_images(dataloader.path, n_images)\n",
    "# print('Loaded images shape:', np.array(images).shape)\n",
    "images = dataloader.greyscale_images(images)\n",
    "# print('Greyscale images shape:', np.array(images).shape)\n",
    "images = dataloader.layer_images(images, n_images)\n",
    "print ('Layered images shape:', images.shape)\n",
    "images = torch.tensor(images, dtype=torch.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38082a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 400\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "torch.Size([4, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "\n",
    "model.cuda()# Move the model to the GPU\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 0.001)\n",
    "\n",
    "BS = 16\n",
    "# Split the dataset into training and testing datasets\n",
    "train_size = int(0.8 * len(images))\n",
    "test_size = len(images) - train_size\n",
    "train_dataset, test_dataset = random_split(images, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders for training and testing datasets\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BS, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BS, shuffle=True)\n",
    "\n",
    "print('Train dataset size:', len(train_dataset))\n",
    "\n",
    "print(type(train_loader))\n",
    "print(train_loader.dataset[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93837770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:01<02:03,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 8550.3535, Validation Loss: 8507.1212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:05<01:23,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Loss: 8445.4629, Validation Loss: 8482.7157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:07<01:28,  1.05it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# for img, _ in train_loader:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# print('img shape:', img.shape)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(img)\n\u001b[0;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, img)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# Define a list to store training loss and validation loss\n",
    "Loss = []\n",
    "Validation_Loss = []\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()  # Set model to training mode\n",
    "    # for img, _ in train_loader:\n",
    "    for idx, img in enumerate(train_loader):\n",
    "        # print('img shape:', img.shape)\n",
    "        img = img.cuda()\n",
    "        \n",
    "        output = model(img)\n",
    "        loss = criterion(output, img)\n",
    "\n",
    "        optimizer.zero_grad() #clears the gradients of all optimized tensors.  This step is necessary because gradients are accumulated by default in PyTorch, and we want to compute fresh gradients for the current batch of data.\n",
    "        loss.backward() # This line computes the gradients of the loss function with respect to the model parameters. These gradients are used to update the model parameters during optimization.\n",
    "        optimizer.step() # This line updates the model parameters using the computed gradients. \n",
    "    Loss.append(loss.item())\n",
    "       \n",
    "\n",
    "    # Calculate validation loss\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        val_loss_sum = 0.0\n",
    "        num_batches = 0\n",
    "        for idx, img in enumerate(test_loader):\n",
    "            img = img.cuda()\n",
    "            output = model(img)\n",
    "            val_loss = criterion(output, img)\n",
    "            val_loss_sum += val_loss.item()\n",
    "            num_batches += 1\n",
    "        val_loss_avg = val_loss_sum / num_batches\n",
    "        Validation_Loss.append(val_loss_avg)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item(), val_loss_avg))\n",
    "\n",
    "plt.plot(Loss, label='Training Loss')\n",
    "plt.plot(Validation_Loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dbb7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "img shape: torch.Size([16, 4, 224, 224])\n",
      "output shape: torch.Size([16, 4, 224, 224])\n",
      "loss shape: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "for idx, img in enumerate(train_loader):\n",
    "    img = img.cuda()\n",
    "    output = model(img)\n",
    "    loss = criterion(output, img)\n",
    "    print('img shape:', img.shape)\n",
    "    print('output shape:', output.shape)\n",
    "    print('loss shape:', loss.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
